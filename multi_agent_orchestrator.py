"""
Phase 2: Multi-Agent Orchestration with LangGraph

Bu modÃ¼l, iki persona ajanÄ±nÄ±n (Erol GÃ¼ngÃ¶r ve Cemil MeriÃ§) paralel Ã§alÄ±ÅŸmasÄ±nÄ± koordine eden
Ã§ok-ajanli orkestrasyon sistemini iÃ§erir. LangGraph kullanarak tool node'larÄ± ve conditional
edge'leri destekler.

Bu system ÅŸu bileÅŸenleri iÃ§erir:
- Graph State: TÃ¼m ajanlarÄ±n durumunu takip eden TypedDict
- Persona Agent Nodes: Her persona iÃ§in ayrÄ± node'lar
- Tool Nodes: Her ajanÄ±n tool Ã§aÄŸrÄ±larÄ±nÄ± yÃ¶neten node'lar
- Synthesizer Node: AjanlarÄ±n Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtiren node
- Memory Node: Sohbet geÃ§miÅŸini gÃ¼ncelleyen node
"""

import asyncio
from typing import Any, Dict, List, Optional, TypedDict, Annotated, Literal
from dataclasses import dataclass

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver

# Import Phase 1 components
from persona_agents import initialize_components, create_persona_agent
from persona_prompts import get_persona_info, list_available_personas

# --- Graph State Definition ---

class GraphState(TypedDict):
    """LangGraph iÃ§in durum yÃ¶netimi."""
    user_query: str
    erol_gungor_agent_output: Optional[Dict[str, Any]]
    cemil_meric_agent_output: Optional[Dict[str, Any]]
    synthesized_answer: Optional[str]
    agent_responses: Optional[Dict[str, str]]
    chat_history: Annotated[List[BaseMessage], add_messages]

# --- Node Functions ---

def erol_gungor_agent_node(state: GraphState, config: RunnableConfig) -> Dict[str, Any]:
    """Erol GÃ¼ngÃ¶r ajanÄ±nÄ± Ã§alÄ±ÅŸtÄ±ran node."""
    
    print(f"\nğŸ¯ DEBUG: Starting Erol GÃ¼ngÃ¶r agent node")
    print(f"ğŸ” DEBUG: User query: {state['user_query']}")
    
    # Get the agent from config
    erol_agent = config.get("configurable", {}).get("erol_agent")
    if not erol_agent:
        print(f"âŒ DEBUG: Erol GÃ¼ngÃ¶r agent not found in config")
        return {
            "erol_gungor_agent_output": {"error": "Erol GÃ¼ngÃ¶r ajanÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ"}
        }
    
    try:
        # Create message for the agent
        messages = [HumanMessage(content=state["user_query"])]
        print(f"ğŸ’¬ DEBUG: Invoking Erol GÃ¼ngÃ¶r agent")
        
        # Invoke the agent
        result = erol_agent.invoke({"messages": messages})
        print(f"âœ… DEBUG: Erol GÃ¼ngÃ¶r agent completed successfully")
        print(f"ğŸ“Š DEBUG: Agent returned {len(result.get('messages', []))} messages")
        
        return {
            "erol_gungor_agent_output": result
        }
        
    except Exception as e:
        print(f"âŒ DEBUG: Error in Erol GÃ¼ngÃ¶r agent node: {str(e)}")
        return {
            "erol_gungor_agent_output": {"error": f"Erol GÃ¼ngÃ¶r ajanÄ± hatasÄ±: {str(e)}"}
        }

def cemil_meric_agent_node(state: GraphState, config: RunnableConfig) -> Dict[str, Any]:
    """Cemil MeriÃ§ ajanÄ±nÄ± Ã§alÄ±ÅŸtÄ±ran node."""
    
    print(f"\nğŸ¯ DEBUG: Starting Cemil MeriÃ§ agent node")
    print(f"ğŸ” DEBUG: User query: {state['user_query']}")
    
    # Get the agent from config
    cemil_agent = config.get("configurable", {}).get("cemil_agent")
    if not cemil_agent:
        print(f"âŒ DEBUG: Cemil MeriÃ§ agent not found in config")
        return {
            "cemil_meric_agent_output": {"error": "Cemil MeriÃ§ ajanÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ"}
        }
    
    try:
        # Create message for the agent
        messages = [HumanMessage(content=state["user_query"])]
        print(f"ğŸ’¬ DEBUG: Invoking Cemil MeriÃ§ agent")
        
        # Invoke the agent
        result = cemil_agent.invoke({"messages": messages})
        print(f"âœ… DEBUG: Cemil MeriÃ§ agent completed successfully")
        print(f"ğŸ“Š DEBUG: Agent returned {len(result.get('messages', []))} messages")
        
        return {
            "cemil_meric_agent_output": result
        }
        
    except Exception as e:
        print(f"âŒ DEBUG: Error in Cemil MeriÃ§ agent node: {str(e)}")
        return {
            "cemil_meric_agent_output": {"error": f"Cemil MeriÃ§ ajanÄ± hatasÄ±: {str(e)}"}
        }

def join_agents_node(state: GraphState, config: RunnableConfig) -> Dict[str, Any]:
    """Ä°ki ajanÄ±n tamamlanmasÄ±nÄ± bekleyen ara node."""
    
    print(f"\nğŸ”„ DEBUG: Join node - checking if both agents completed")
    
    erol_output = state.get("erol_gungor_agent_output")
    cemil_output = state.get("cemil_meric_agent_output")
    
    print(f"âœ“ DEBUG: Erol GÃ¼ngÃ¶r output available: {erol_output is not None}")
    print(f"âœ“ DEBUG: Cemil MeriÃ§ output available: {cemil_output is not None}")
    
    # This node doesn't modify state, just serves as a junction
    return {}

def synthesize_response_node(state: GraphState, config: RunnableConfig) -> Dict[str, Any]:
    """Ä°ki ajanÄ±n yanÄ±tlarÄ±nÄ± birleÅŸtiren node."""
    
    print(f"\nğŸ”„ DEBUG: Starting synthesis node")
    
    # Get the LLM from config
    llm = config.get("configurable", {}).get("llm")
    if not llm:
        print(f"âŒ DEBUG: LLM not found in config for synthesis")
        return {"synthesized_answer": "Sentez iÃ§in dil modeli yapÄ±landÄ±rÄ±lmamÄ±ÅŸ."}
    
    # Extract responses from agent outputs
    erol_response = ""
    cemil_response = ""
    
    # Process Erol GÃ¼ngÃ¶r's output
    erol_output = state.get("erol_gungor_agent_output", {})
    if erol_output and "messages" in erol_output:
        erol_messages = erol_output["messages"]
        if erol_messages:
            last_message = erol_messages[-1]
            erol_response = last_message.content if hasattr(last_message, 'content') else str(last_message)
    elif erol_output and "error" in erol_output:
        erol_response = f"Erol GÃ¼ngÃ¶r yanÄ±tÄ± alÄ±namadÄ±: {erol_output['error']}"
    
    # Process Cemil MeriÃ§'s output
    cemil_output = state.get("cemil_meric_agent_output", {})
    if cemil_output and "messages" in cemil_output:
        cemil_messages = cemil_output["messages"]
        if cemil_messages:
            last_message = cemil_messages[-1]
            cemil_response = last_message.content if hasattr(last_message, 'content') else str(last_message)
    elif cemil_output and "error" in cemil_output:
        cemil_response = f"Cemil MeriÃ§ yanÄ±tÄ± alÄ±namadÄ±: {cemil_output['error']}"
    
    print(f"ğŸ“ DEBUG: Erol GÃ¼ngÃ¶r response length: {len(erol_response)} characters")
    print(f"ğŸ“ DEBUG: Cemil MeriÃ§ response length: {len(cemil_response)} characters")
    
    # Create synthesis prompt
    synthesis_prompt = f"""Sen, TÃ¼rk entelektÃ¼el geleneÄŸini anlayan ve farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ±nÄ± sentezleyebilen bir asistansÄ±n.

KullanÄ±cÄ± Sorusu: {state['user_query']}

Erol GÃ¼ngÃ¶r'Ã¼n YanÄ±tÄ±:
{erol_response}

Cemil MeriÃ§'in YanÄ±tÄ±:
{cemil_response}

GÃ¶revin: Bu iki entelektÃ¼elin yanÄ±tlarÄ±nÄ± birleÅŸtirerek tek bir tutarlÄ±, kapsamlÄ± yanÄ±t oluÅŸturmak. 

Sentez yaparken:
1. Her iki perspektifi de saygÄ±yla dahil et
2. Ortak noktalarÄ± vurgula
3. FarklÄ± gÃ¶rÃ¼ÅŸleri de belirt ve bunlarÄ± tamamlayÄ±cÄ± olarak sun
4. TekrarlarÄ± Ã¶nle
5. AkÄ±cÄ±, tutarlÄ± bir metin oluÅŸtur
6. Her iki entelektÃ¼elin katkÄ±sÄ±nÄ± acknowledge et

BaÅŸlÄ±klar kullanma, doÄŸrudan kapsamlÄ± bir yanÄ±t ver."""
    
    try:
        print(f"ğŸ§  DEBUG: Sending synthesis request to Gemini...")
        synthesis_result = llm.invoke(synthesis_prompt)
        
        synthesized_text = synthesis_result.content if hasattr(synthesis_result, 'content') else str(synthesis_result)
        print(f"âœ… DEBUG: Synthesis completed successfully")
        print(f"ğŸ“ DEBUG: Synthesized response length: {len(synthesized_text)} characters")
        
        # Prepare individual agent responses for frontend
        agent_responses = {
            "Erol GÃ¼ngÃ¶r": erol_response,
            "Cemil MeriÃ§": cemil_response
        }
        
        print(f"ğŸ¯ DEBUG: Agent responses prepared for frontend: {list(agent_responses.keys())}")
        
        return {
            "synthesized_answer": synthesized_text,
            "agent_responses": agent_responses
        }
        
    except Exception as e:
        print(f"âŒ DEBUG: Error during synthesis: {str(e)}")
        return {
            "synthesized_answer": f"Sentez hatasÄ±: {str(e)}",
            "agent_responses": {
                "Erol GÃ¼ngÃ¶r": erol_response if erol_response else "YanÄ±t alÄ±namadÄ±",
                "Cemil MeriÃ§": cemil_response if cemil_response else "YanÄ±t alÄ±namadÄ±"
            }
        }

def update_history_node(state: GraphState, config: RunnableConfig) -> Dict[str, Any]:
    """Sohbet geÃ§miÅŸini gÃ¼ncelleyen node."""
    
    print(f"\nğŸ“š DEBUG: Updating chat history")
    
    # Create messages for history
    user_message = HumanMessage(content=state["user_query"])
    ai_message = AIMessage(content=state.get("synthesized_answer", "YanÄ±t oluÅŸturulamadÄ±"))
    
    print(f"ğŸ’¬ DEBUG: Adding user message and AI response to history")
    print(f"ğŸ“Š DEBUG: Current history length: {len(state.get('chat_history', []))}")
    
    new_messages = [user_message, ai_message]
    
    print(f"âœ… DEBUG: Chat history updated with {len(new_messages)} new messages")
    
    return {"chat_history": new_messages}

# --- Graph Builder ---

class MultiAgentOrchestrator:
    """Multi-agent orchestration system using LangGraph."""
    
    def __init__(self):
        """Orchestrator'Ä± baÅŸlatÄ±r."""
        self.graph = None
        self.qdrant_client = None
        self.embedding_model = None
        self.llm = None
        self.agents = {}
        
    def initialize(self):
        """TÃ¼m bileÅŸenleri baÅŸlatÄ±r."""
        
        print(f"\nğŸš€ DEBUG: Initializing Multi-Agent Orchestrator")
        
        # Initialize Phase 1 components
        print(f"ğŸ”§ DEBUG: Initializing Phase 1 components...")
        self.qdrant_client, self.embedding_model, self.llm = initialize_components()
        
        if not all([self.qdrant_client, self.embedding_model, self.llm]):
            raise Exception("Phase 1 bileÅŸenleri baÅŸlatÄ±lamadÄ±")
        
        print(f"âœ… DEBUG: Phase 1 components initialized successfully")
        
        # Create persona agents
        print(f"ğŸ‘¥ DEBUG: Creating persona agents...")
        available_personas = list_available_personas()
        
        for persona_key in available_personas:
            try:
                agent = create_persona_agent(
                    persona_key, 
                    self.qdrant_client, 
                    self.embedding_model, 
                    self.llm
                )
                self.agents[persona_key] = agent
                persona_info = get_persona_info(persona_key)
                print(f"âœ“ DEBUG: Created agent for {persona_info['name']}")
            except Exception as e:
                print(f"âŒ DEBUG: Failed to create agent for {persona_key}: {e}")
                raise
        
        print(f"âœ… DEBUG: All persona agents created successfully")
        
        # Build the graph
        print(f"ğŸ—ï¸ DEBUG: Building LangGraph workflow...")
        self._build_graph()
        print(f"âœ… DEBUG: Multi-Agent Orchestrator initialized successfully")
    
    def _build_graph(self):
        """LangGraph workflow'unu oluÅŸturur."""
        
        print(f"\nğŸ—ï¸ DEBUG: Building state graph...")
        
        # Create the state graph
        workflow = StateGraph(GraphState)
        
        # Add nodes
        print(f"â• DEBUG: Adding nodes to graph...")
        workflow.add_node("erol_gungor_agent", erol_gungor_agent_node)
        workflow.add_node("cemil_meric_agent", cemil_meric_agent_node)
        workflow.add_node("join_agents", join_agents_node)
        workflow.add_node("synthesize_response", synthesize_response_node)
        workflow.add_node("update_history", update_history_node)
        
        # Add edges
        print(f"ğŸ”— DEBUG: Adding edges to graph...")
        
        # Entry point: Start with both agents in parallel
        workflow.add_edge(START, "erol_gungor_agent")
        workflow.add_edge(START, "cemil_meric_agent")
        
        # Both agents feed into join node
        workflow.add_edge("erol_gungor_agent", "join_agents")
        workflow.add_edge("cemil_meric_agent", "join_agents")
        
        # Sequential flow after joining
        workflow.add_edge("join_agents", "synthesize_response")
        workflow.add_edge("synthesize_response", "update_history")
        workflow.add_edge("update_history", END)
        
        # Compile the graph
        print(f"âš™ï¸ DEBUG: Compiling graph...")
        checkpointer = MemorySaver()
        self.graph = workflow.compile(checkpointer=checkpointer)
        
        print(f"âœ… DEBUG: Graph compiled successfully")
    
    def invoke(self, user_query: str, thread_id: str = "default") -> Dict[str, Any]:
        """Orchestrator'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r."""
        
        print(f"\nğŸ¯ DEBUG: Invoking Multi-Agent Orchestrator")
        print(f"ğŸ’¬ DEBUG: User query: {user_query}")
        print(f"ğŸ§µ DEBUG: Thread ID: {thread_id}")
        
        # Prepare initial state
        initial_state = {
            "user_query": user_query,
            "erol_gungor_agent_output": None,
            "cemil_meric_agent_output": None,
            "synthesized_answer": None,
            "agent_responses": None,
            "chat_history": []
        }
        
        # Prepare config with agents
        config = {
            "configurable": {
                "erol_agent": self.agents.get("erol_gungor"),
                "cemil_agent": self.agents.get("cemil_meric"),
                "llm": self.llm,
                "thread_id": thread_id
            }
        }
        
        try:
            print(f"ğŸš€ DEBUG: Starting graph execution...")
            result = self.graph.invoke(initial_state, config)
            
            print(f"âœ… DEBUG: Graph execution completed successfully")
            print(f"ğŸ“Š DEBUG: Final state keys: {list(result.keys())}")
            
            return result
            
        except Exception as e:
            print(f"âŒ DEBUG: Error during graph execution: {str(e)}")
            return {
                "error": f"Orchestration hatasÄ±: {str(e)}",
                "user_query": user_query,
                "synthesized_answer": "Sistem hatasÄ± nedeniyle yanÄ±t oluÅŸturulamadÄ±."
            }

# --- Convenience Functions ---

def create_orchestrator() -> MultiAgentOrchestrator:
    """Yeni bir Multi-Agent Orchestrator oluÅŸturur ve baÅŸlatÄ±r."""
    
    orchestrator = MultiAgentOrchestrator()
    orchestrator.initialize()
    return orchestrator

def run_multi_agent_query(query: str, thread_id: str = "default") -> Dict[str, Any]:
    """Tek seferlik multi-agent sorgu Ã§alÄ±ÅŸtÄ±rÄ±r."""
    
    orchestrator = create_orchestrator()
    return orchestrator.invoke(query, thread_id) 